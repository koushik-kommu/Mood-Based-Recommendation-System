# ðŸŽ­ MoodSync â€” Mood-Based Song & Movie Recommendation System

A machine learning-powered web application that detects your emotional state through **facial expression analysis (CNN)** and a **dynamic questionnaire**, then recommends mood-matched **songs** and **movies** with working links.

---

## ðŸ“‹ Table of Contents

- [Features](#-features)
- [Project Architecture](#-project-architecture)
- [Steps to Execute the Project](#-steps-to-execute-the-project)
- [Project Lifecycle (Start to Termination)](#-project-lifecycle-start-to-termination)
- [Tech Stack](#-tech-stack)

---

## âœ¨ Features

| Feature | Description |
|---|---|
| ðŸŽ¯ Facial Emotion Recognition | CNN trained on FER-2013 dataset (59.9% accuracy) |
| ðŸ“ Dynamic Questionnaire | Adaptive branching questions that change based on answers |
| ðŸ”€ Mood Fusion Engine | Weighted combination (60% CNN + 40% Questionnaire) |
| ðŸŽµ Song Recommendations | 60 songs across 6 moods with YouTube links |
| ðŸŽ¬ Movie Recommendations | 60 movies across 6 moods with OTT platform links |
| ðŸŒ™ Modern Dark UI | Glassmorphism, particle animations, responsive design |

**Supported Moods:** Happy, Sad, Angry, Neutral, Excited, Stressed

---

## ðŸ— Project Architecture

```
mood/
â”œâ”€â”€ app.py                     # Flask application (main entry point)
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ schema.sql             # SQLite schema (songs, movies, mood_history)
â”‚   â”œâ”€â”€ db_utils.py            # DB connection & query helpers
â”‚   â””â”€â”€ seed_data.py           # Seed data (60 songs + 60 movies)
â”œâ”€â”€ emotion/
â”‚   â”œâ”€â”€ face_detector.py       # Haar Cascade face detection + preprocessing
â”‚   â”œâ”€â”€ emotion_model.py       # CNN architecture (3 conv blocks)
â”‚   â”œâ”€â”€ train_model.py         # Model training script
â”‚   â”œâ”€â”€ predict.py             # Prediction API
â”‚   â””â”€â”€ emotion_model.h5       # Trained model weights (generated after training)
â”œâ”€â”€ questionnaire/
â”‚   â”œâ”€â”€ questions.py           # Adaptive question tree (13 nodes)
â”‚   â””â”€â”€ scorer.py              # Response scoring & normalization
â”œâ”€â”€ fusion/
â”‚   â””â”€â”€ mood_fusion.py         # Weighted mood fusion logic
â”œâ”€â”€ recommender/
â”‚   â””â”€â”€ engine.py              # Content-based recommendation engine
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ base.html              # Base layout (dark theme)
â”‚   â”œâ”€â”€ index.html             # Step 1: Image upload / webcam
â”‚   â”œâ”€â”€ questionnaire.html     # Step 2: Adaptive questionnaire
â”‚   â””â”€â”€ results.html           # Step 3: Mood & recommendations
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/style.css          # Glassmorphism dark theme
â”‚   â””â”€â”€ js/main.js             # Particle animations
â””â”€â”€ tests/
    â””â”€â”€ __init__.py
```

---

## ðŸš€ Steps to Execute the Project

### Step 1: Clone the Repository
```bash
git clone https://github.com/koushik-kommu/Mood-Based-Recommendation-System.git
cd Mood-Based-Recommendation-System
```

### Step 2: Install Dependencies
```bash
pip3 install -r requirements.txt
pip3 install scipy kagglehub  # Additional dependencies for CNN training
```

### Step 3: Train the CNN Model (One-Time Setup)
```bash
python3 -m emotion.train_model
```
> This automatically downloads the FER-2013 dataset (~60 MB) from Kaggle and trains the CNN.  
> Training takes ~15 minutes and saves the model to `emotion/emotion_model.h5`.  
> **Note:** The app works without this step using the questionnaire-only path.

### Step 4: Run the Application
```bash
python3 app.py
```
The database is automatically initialized and seeded on first run.

### Step 5: Open in Browser
```
http://localhost:5000
```

### Step 6: Use the Application
1. **Upload a photo** or **use your webcam** for facial emotion detection
2. **Answer 4 adaptive questions** in the dynamic questionnaire
3. **View your detected mood** and get personalized song & movie recommendations

### Step 7: Stop the Server
Press `Ctrl + C` in the terminal to stop Flask.

---

## ðŸ”„ Project Lifecycle (Start to Termination)

### Phase 1 â€” Initialization (Automatic on First Run)
```
python3 app.py
```
When the app starts for the first time:
1. **Database Creation** â†’ SQLite DB is created at `database/mood_recommendations.db`
2. **Schema Setup** â†’ Tables `songs`, `movies`, `mood_history` are created from `schema.sql`
3. **Data Seeding** â†’ 60 songs and 60 movies are inserted across 6 mood categories
4. **Flask Server** â†’ Starts on `http://0.0.0.0:5000` in debug mode

### Phase 2 â€” User Input (Step 1: Face Analysis)
```
Route: GET /  â†’  POST /upload  or  POST /api/capture
```
1. User opens the landing page at `/`
2. **Option A â€” Upload Photo:** User selects an image file â†’ sent to `/upload`
3. **Option B â€” Webcam Capture:** Browser captures a frame â†’ sent to `/api/capture`
4. **Option C â€” Skip:** User clicks "Skip this step" â†’ sent to `/api/skip-image`

**Processing (if image provided):**
- Haar Cascade detects faces in the image
- Face is cropped, converted to grayscale, resized to 48Ã—48
- CNN predicts emotion probabilities across 7 FER classes
- Probabilities are mapped to 6 project moods and stored in session

### Phase 3 â€” User Input (Step 2: Questionnaire)
```
Route: GET /questionnaire  â†’  GET /api/first-question  â†’  GET /api/question/<id>
```
1. First question is loaded via `/api/first-question`
2. User selects an answer â†’ triggers loading the next branching question
3. Questions adapt dynamically based on previous answers (13 possible paths)
4. After 4 questions, responses are submitted to `/api/submit-questionnaire`

**Processing:**
- Each answer carries mood scores (e.g., `{Happy: 0.3, Excited: 0.7}`)
- Scores are aggregated and normalized to sum to 1.0
- Result is stored in session

### Phase 4 â€” Mood Fusion & Recommendation (Step 3: Results)
```
Route: GET /results
```
**Fusion Logic:**
- If both inputs available: `Final = 0.6 Ã— CNN + 0.4 Ã— Questionnaire`
- If only one input: uses that input at 100%
- Dominant mood (highest score) is selected

**Recommendation:**
- SQLite is queried for songs and movies matching the dominant mood
- 5 random songs with YouTube links are returned
- 5 random movies with OTT platform links are returned
- Results are logged to `mood_history` table

**Display:**
- Mood emoji, label, and confidence percentage
- Source badges (CNN / Questionnaire)
- Animated mood breakdown bar chart
- Song and movie recommendation cards with clickable links

### Phase 5 â€” Repeat or Terminate
- **Try Again:** User clicks "Try Again" â†’ redirects to `/` (Phase 2)
- **History:** Each session is logged in `mood_history` for tracking
- **Terminate:** Press `Ctrl + C` in terminal to stop the Flask server

---

## ðŸ›  Tech Stack

| Layer | Technology |
|---|---|
| Backend | Python 3, Flask |
| ML Model | TensorFlow/Keras CNN (FER-2013) |
| Face Detection | OpenCV Haar Cascade |
| Database | SQLite |
| Frontend | HTML5, CSS3 (Glassmorphism), Vanilla JS |
| Dataset | FER-2013 (28,709 images, 7 emotions) |

---

## ðŸ‘¤ Author

**Kommu Koushik**

---
